{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing and Exploration\n",
    "## Project - Dishwasher-safe or Not\n",
    "This notebook processes the images of utensils and cookware and creates a dataset for training a classifier which classifies whether an object is dishwasher-safe or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "\n",
    "!pip3 install tensorflow-estimator==2.1\n",
    "\n",
    "!pip3 install tensorflow\n",
    "\n",
    "!python3 -m pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Image Preprocessing\n",
    "\n",
    "The following code iterates through all images in the given directory and converts raw image to pre-processed image by performing the following steps:\n",
    "- crop image to square \n",
    "- resize image to 256x256\n",
    "\n",
    "Pre-requisites:\n",
    "Make sure the image is a square and at the center of the image or the object might get cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SIZE = 256, 256\n",
    "raw_data_dir = '/Users/anushree/Desktop/Dishwasher-safe Or Not/Data/raw_data'\n",
    "processed_data_dir = '/Users/anushree/Desktop/Dishwasher-safe Or Not/Data/processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_image(filepath):\n",
    "    im = Image.open(filepath)\n",
    "    # plt.imshow(np.asarray(im))\n",
    "    # plt.show()\n",
    "\n",
    "    # Find dimensions of square from current dimensions\n",
    "    # New dimension will be the NxN where N is min(width,height)\n",
    "    width, height = im.size   \n",
    "    new_width = min(width, height)\n",
    "    new_height = min(width, height)\n",
    "\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop image to square\n",
    "    im_cropped = im.crop((left, top, right, bottom))\n",
    "    # print(im_cropped.size)\n",
    "    # plt.imshow(np.asarray(im_cropped))\n",
    "    # plt.show()\n",
    "\n",
    "    # Resize image to 256x256\n",
    "    im_cropped.thumbnail(SIZE, Image.Resampling.LANCZOS)\n",
    "    # plt.imshow(np.asarray(im_cropped))\n",
    "    # plt.show()\n",
    "    im_cropped.save(processed_data_dir+filepath.split('/')[-1])\n",
    "\n",
    "ext = ['JPG', 'jpeg', 'png', 'jpg', 'gif', 'webp']\n",
    "# iterate over files\n",
    "for filename in os.listdir(raw_data_dir):\n",
    "    f = os.path.join(raw_data_dir, filename)\n",
    "    # checking if it is an image file\n",
    "    if os.path.isfile(f) and filename.split('.')[-1] in ext:\n",
    "        print(f)\n",
    "        crop_resize_image(f)\n",
    "\n",
    "\n",
    "# crop_resize_image('/Users/anushree/Desktop/Dishwasher-safe Or Not/Data/raw_data/teaspoonraw29.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Exploration\n",
    "The following code helps to visualize cluster of similar images using KNN algorithm.\n",
    "The features of the image are extracted using VGG and reduced using VGG before using in the KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34\n",
    "# for loading/processing the images\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# models\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/Users/anushree/Desktop/Dishwasher-safe Or Not/Data/final_data/not-dishwasher-safe/\"\n",
    "p = r\"/Users/anushree/Desktop/Dishwasher-safe Or Not/Data/data_features.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Extract features using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "        # load the image as a 224x224 array\n",
    "        img = load_img(file, target_size=(224, 224))\n",
    "        # convert from 'PIL.Image.Image' to numpy array\n",
    "        img = np.array(img)\n",
    "        # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "        reshaped_img = img.reshape(1, 224, 224, 3)\n",
    "        # prepare image for model\n",
    "        imgx = preprocess_input(reshaped_img)\n",
    "        # get the feature vector\n",
    "        features = model.predict(imgx, use_multiprocessing=True)\n",
    "        return features\n",
    "\n",
    "def extract_and_save_features():\n",
    "    # change the working directory to the path where the images are located\n",
    "    os.chdir(data_path)\n",
    "\n",
    "    # this list holds all the image filename\n",
    "    utensils = []\n",
    "\n",
    "    for path, subdirs, files in os.walk(data_path):\n",
    "        # loops through each file in the directory\n",
    "        for file in files:\n",
    "            # adds only the image files to the utensils list\n",
    "            if file.endswith(('JPG', 'jpeg', 'png', 'jpg', 'gif', 'webp')):\n",
    "                utensils.append(os.path.join(path,file))\n",
    "    print(utensils[:10])\n",
    "\n",
    "#     # load the image as a 224x224 array\n",
    "#     img = load_img(utensils[0], target_size=(256,256))\n",
    "#     # convert from 'PIL.Image.Image' to numpy array\n",
    "#     img = np.array(img)\n",
    "#     print(img.shape)\n",
    "\n",
    "    model = VGG16()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # loop through each image in the dataset\n",
    "    for utensil in utensils:\n",
    "        # try to extract the features and update the dictionary\n",
    "        try:\n",
    "            feat = extract_features(utensil, model)\n",
    "            data[utensil] = feat\n",
    "        # if something fails, save the extracted features as a pickle file (optional)\n",
    "        except:\n",
    "            print(\"Error:\",utensil)\n",
    "            with open(p, 'wb') as file:\n",
    "                pickle.dump(data, file)\n",
    "    \n",
    "    with open(p, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "        \n",
    "\n",
    "extract_and_save_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create clusters using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lets you view a cluster (based on identifier)\n",
    "def view_cluster(cluster,groups):\n",
    "    plt.figure(figsize=(25, 25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 30:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:29]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(10, 10, index + 1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_clusters(data):\n",
    "    # get a list of the filenames\n",
    "    filenames = np.array(list(data.keys()))\n",
    "    # get a list of just the features\n",
    "    feat = np.array(list(data.values()))\n",
    "    print(feat.shape)\n",
    "    # reshape so that there are 210 samples of 4096 vectors\n",
    "    feat = feat.reshape(-1, 4096)\n",
    "\n",
    "    # reduce the amount of dimensions in the feature vector\n",
    "    pca = PCA(n_components=500)\n",
    "    pca.fit(feat)\n",
    "    x = pca.transform(feat)\n",
    "    print(f\"Components before PCA: {feat.shape[1]}\")\n",
    "    print(f\"Components after PCA: {pca.n_components}\")\n",
    "\n",
    "    # cluster feature vectors\n",
    "    kmeans = KMeans(n_clusters=36, random_state=22)\n",
    "    kmeans.fit(x)\n",
    "\n",
    "    # holds the cluster id and the images { id: [images] }\n",
    "    groups = {}\n",
    "    for file, cluster in zip(filenames, kmeans.labels_):\n",
    "        if cluster not in groups.keys():\n",
    "            groups[cluster] = []\n",
    "            groups[cluster].append(file)\n",
    "        else:\n",
    "            groups[cluster].append(file)\n",
    "\n",
    "    print(groups[0])\n",
    "\n",
    "    for cluster in groups.keys():\n",
    "        view_cluster(cluster,groups)\n",
    "        \n",
    "#     # this is just incase you want to see which value for k might be the best\n",
    "#     sse = []\n",
    "#     list_k = list(range(3, 70))\n",
    "    \n",
    "#     for k in list_k:\n",
    "#         km = KMeans(n_clusters=k, random_state=22)\n",
    "#         km.fit(x)\n",
    "    \n",
    "#         sse.append(km.inertia_)\n",
    "    \n",
    "#     # Plot sse against k\n",
    "#     plt.figure(figsize=(6, 6))\n",
    "#     plt.plot(list_k, sse)\n",
    "#     plt.xlabel(r'Number of clusters *k*')\n",
    "#     plt.ylabel('Sum of squared distance');\n",
    "#     plt.show()\n",
    "\n",
    "with (open(p, \"rb\")) as file:\n",
    "    data = pickle.load(file)\n",
    "    create_clusters(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
